{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T22:42:30.010016Z",
     "start_time": "2019-02-27T22:42:29.920459Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import log_loss,confusion_matrix,classification_report,roc_curve,auc, f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy import sparse\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "from pymongo import MongoClient, InsertOne, DeleteOne, ReplaceOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T22:37:44.072303Z",
     "start_time": "2019-02-27T22:37:44.051096Z"
    }
   },
   "outputs": [],
   "source": [
    "incel_df = pd.read_csv('new_IncelTears_posts.csv')\n",
    "slate_df = pd.read_csv('new_slatestarcodex_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T22:46:22.923816Z",
     "start_time": "2019-02-27T22:46:22.912506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['titles',\n",
       " 'test_insert',\n",
       " 'mycollection',\n",
       " 'overnight_reddit',\n",
       " 'reddit_overnight']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "db = client[\"reddit\"]\n",
    "db.collection_names()\n",
    "#db.create_collection(\"test_insert\")\n",
    "#test_collection = db.get_collection('test_insert')\n",
    "\n",
    "#db.create_collection(\"titles\")\n",
    "#titles_collection = db.get_collection('titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T22:47:24.085213Z",
     "start_time": "2019-02-27T22:47:24.081720Z"
    }
   },
   "outputs": [],
   "source": [
    "titles_collection = db.get_collection('titles')\n",
    "overnight_reddit_collection = db.get_collection('overnight_reddit')\n",
    "reddit_overnight_collection = db.get_collection('reddit_overnight') \n",
    "#list(titles_collection.find({'subreddit':'IncelTears', 'over_18':False}).limit(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T23:14:31.657025Z",
     "start_time": "2019-02-27T23:14:29.472780Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('fit_vect.pickle', 'rb') as handle:\n",
    "     vect_word = pickle.load(handle)\n",
    "        \n",
    "### IMPORTS PICKLED LR MODEL\n",
    "with open('lr_model.pickle', 'rb') as handle:\n",
    "     lr = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T23:24:34.771213Z",
     "start_time": "2019-02-27T23:24:34.766860Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_X_submittors_to_subreddit(subreddit, X): \n",
    "    subreddit_list = list(titles_collection.find({'subreddit':subreddit}))\n",
    "    subreddit_df = pd.DataFrame(subreddit_list)\n",
    "    subreddit_df = subreddit_df[subreddit_df['author'] != '[deleted]']\n",
    "    top_X_subreddit_submittors = list(subreddit_df.groupby('author').count().sort_values(by=['_id'], ascending=False)[:X].index.values)\n",
    "    return top_X_subreddit_submittors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T23:47:57.039884Z",
     "start_time": "2019-02-27T23:47:57.033952Z"
    }
   },
   "outputs": [],
   "source": [
    "def score_user(subreddit, user):\n",
    "    \"\"\" \n",
    "    This function takes in a subreddit title and user, prints out their toxicity score\n",
    "    and returns a lot of the process for further analysis.\n",
    "    \n",
    "    Right now what it returns are:\n",
    "        toxic_percent = the users' score\n",
    "        toxic_sample, safe sample = 10 sample text to eyeball the usefulness of the model\n",
    "        \n",
    "        These below should eventually be removed.\n",
    "        user_probs = This is currently just appended into the function, eventually it should be pulled out.\n",
    "        Right now what it returns is a predict_proba score instead of a 0,1 for the toxicity.\n",
    "        user_submissions = This is all of the input data which helped me map the worst predict probas\n",
    "        back to their titles to see what the worst predict proba's are. This definitely should also be separated \n",
    "        eventually.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #top_author = top_3_slate_submittors[0]\n",
    "    user_submissions = list(titles_collection.find({'subreddit':subreddit, 'author':user}))\n",
    "    user_text = np.array([i['title'] for i in user_submissions])\n",
    "    user_vect = vect_word.transform(user_text)\n",
    "    user_preds = lr.predict(user_vect)\n",
    "    user_probs = lr.predict_proba(user_vect) \n",
    "    \n",
    "    toxic_percent = user_preds.sum()/user_preds.shape[0]\n",
    "    print(f'Percentage of {subreddit} user {user} titles predicted as toxic is {round(toxic_percent,2)*100}%')\n",
    "    \n",
    "    toxic_sample = user_text[np.isin(user_preds, 1)][:10] \n",
    "    safe_sample = user_text[np.isin(user_preds, 0)][:10] \n",
    "\n",
    "    return toxic_percent, toxic_sample, safe_sample, user_probs, user_submissions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T23:36:21.035281Z",
     "start_time": "2019-02-27T23:36:19.746766Z"
    }
   },
   "outputs": [],
   "source": [
    "slate_star_top_3 = get_top_X_submittors_to_subreddit('slatestarcodex', 3)\n",
    "incel_tears_top_3 = get_top_X_submittors_to_subreddit('IncelTears', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T23:48:02.159155Z",
     "start_time": "2019-02-27T23:48:01.736895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of slatestarcodex user werttrew titles predicted as toxic is 5.0%\n",
      "Percentage of slatestarcodex user gwern titles predicted as toxic is 6.0%\n",
      "Percentage of slatestarcodex user dwaxe titles predicted as toxic is 5.0%\n",
      "Percentage of IncelTears user RidingChad titles predicted as toxic is 35.0%\n",
      "Percentage of IncelTears user BrazilianSigma titles predicted as toxic is 37.0%\n",
      "Percentage of IncelTears user caspertruth666 titles predicted as toxic is 31.0%\n"
     ]
    }
   ],
   "source": [
    "slate_top_3_scores_and_samples = [score_user('slatestarcodex',i) for i in slate_star_top_3]\n",
    "incel_top_3_scores_and_samples = [score_user('IncelTears',i) for i in incel_tears_top_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T23:52:26.748003Z",
     "start_time": "2019-02-27T23:52:26.742727Z"
    }
   },
   "outputs": [],
   "source": [
    "#top users' predict proba's sorted by the ones most likely to be toxic listing top 5. - SLATE\n",
    "user_predict_proba = [(idx, value) for idx, value in enumerate(slate_top_3_scores_and_samples[0][3])]\n",
    "check_5_highest_toxicity = sorted(user_predict_proba, reverse=True, key=lambda x: x[1][1])[:5]\n",
    "five_highest_text = [slate_top_3_scores_and_samples[0][4][i[0]]['title'] for i in check_5_highest_toxicity]\n",
    "five_highest_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T23:53:14.970373Z",
     "start_time": "2019-02-27T23:53:14.964962Z"
    }
   },
   "outputs": [],
   "source": [
    "#top users' predict proba's sorted by the ones most likely to be toxic listing top 5. - INCEL\n",
    "user_predict_proba = [(idx, value) for idx, value in enumerate(incel_top_3_scores_and_samples[0][3])]\n",
    "check_5_highest_toxicity = sorted(user_predict_proba, reverse=True, key=lambda x: x[1][1])[:5]\n",
    "five_highest_text = [slate_top_3_scores_and_samples[0][4][i[0]]['title'] for i in check_5_highest_toxicity]\n",
    "five_highest_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
