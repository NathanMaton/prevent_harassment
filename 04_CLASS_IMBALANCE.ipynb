{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d894877c-753f-4947-a6a0-8c100b8af6b2",
    "_uuid": "3a208d285d49bbe7c35827de8416e3b7c5c061ae"
   },
   "source": [
    "## Toxic comment classification\n",
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:39:23.498938Z",
     "start_time": "2019-03-01T21:39:22.393737Z"
    },
    "_cell_guid": "fd0d94af-8dcd-4258-92fc-d1c304215a9a",
    "_uuid": "d2539467b6d1fa164da8c43825cd30a124eb9c47"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import log_loss,confusion_matrix,classification_report,roc_curve,auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, precision_recall_curve \n",
    "from sklearn.metrics import confusion_matrix, f1_score, fbeta_score, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy import sparse\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#WARNINGS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pymongo import MongoClient, InsertOne, DeleteOne, ReplaceOne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4043cdf-f986-42bc-ad09-ea124e152507",
    "_uuid": "6b388128bf18f28c29d66377e9deb5f1ea8067f1"
   },
   "source": [
    "## Read data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:39:25.371090Z",
     "start_time": "2019-03-01T21:39:24.405971Z"
    },
    "_cell_guid": "7ce644b7-5332-40d7-a827-15f6897be5e8",
    "_uuid": "d1134807fc7b6c604f7fbdd42e0f27e69a834337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns in the train data set: (159571, 8)\n"
     ]
    }
   ],
   "source": [
    "toxic = pd.read_csv('toxicity_data/train.csv') #there's also a test dataset but it doesn't have labels b/c kaggle.\n",
    "print('Number of rows and columns in the train data set:',toxic.shape)\n",
    "\n",
    "#unlabeled data\n",
    "incel_df = pd.read_csv('new_IncelTears_posts.csv')\n",
    "slate_df = pd.read_csv('new_slatestarcodex_posts.csv')\n",
    "\n",
    "raw_toxic = toxic\n",
    "small_toxic = toxic #can add a .sample to make things run quicker here.\n",
    "\n",
    "#turn multi-class into single class classifier\n",
    "target_col = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n",
    "y = small_toxic[target_col]\n",
    "y['sum'] = y.sum(axis=1).astype(bool).astype(int) \n",
    "\n",
    "# try undersampling\n",
    "small_toxic['target']=y['sum']\n",
    "neg_sample = small_toxic[small_toxic['target']==0].sample(16000)\n",
    "pos_sample = small_toxic[small_toxic['target']==1].sample(16000)\n",
    "all_df = pd.concat([neg_sample,pos_sample])\n",
    "\n",
    "# ##Original code, doesn't do as well as undersampled code -- in case you want to try it.\n",
    "# X_train, X_holdout, y_train, y_holdout = train_test_split(small_toxic.drop('target',axis=1), small_toxic['target'], test_size=0.2, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# this is for undersampling\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(all_df.drop('target',axis=1), all_df['target'], test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3a73e542-178e-4b3e-ad8c-87e9dc659762",
    "_uuid": "2daff7626ba426dbfa0172b6c3a4351af27cd4e9"
   },
   "source": [
    "## Text preprocessing - TF-IDF up to trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:39:32.352285Z",
     "start_time": "2019-03-01T21:39:25.645480Z"
    },
    "_cell_guid": "93502afb-68c7-4cc2-ad03-f71d2b2cbf2a",
    "_uuid": "3d1747c73d3c67c93eb4e7e81de4400276f0580c"
   },
   "outputs": [],
   "source": [
    "vect_word = TfidfVectorizer(max_features=20000, lowercase=True, analyzer='word',\n",
    "                        stop_words= 'english',ngram_range=(1,3),dtype=np.float32)\n",
    "tr_vect = vect_word.fit_transform(X_train['comment_text'])\n",
    "ts_vect = vect_word.transform(X_test['comment_text'])\n",
    "holdout_vect = vect_word.transform(X_holdout['comment_text'])\n",
    "\n",
    "incel_vect = vect_word.transform(incel_df['title'])\n",
    "slate_vect = vect_word.transform(slate_df['title'])\n",
    "#took 30-50 seconds on 150k samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:39:49.593552Z",
     "start_time": "2019-03-01T21:39:32.354454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic regression': 0.884286176528254, 'Random Forest': 0.8233909091930197}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_model(model, X_train, y_train):\n",
    "    cv_results = cross_validate(model, X_train, y_train, cv=5, scoring='f1')\n",
    "    return np.mean(cv_results['test_score'])\n",
    "\n",
    "def model_baseline(X_train, y_train):\n",
    "    \"\"\"This takes in training and validation data and runs it through\n",
    "    6 basic classification models and scores them based on recall\"\"\"\n",
    "\n",
    "    lm2 = LogisticRegression(C=2,random_state = 42,class_weight = 'balanced') #all features\n",
    "    lm2_score = score_model(lm2, X_train, y_train)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf_score = score_model(rf, X_train, y_train)\n",
    "\n",
    "    res = {\n",
    "        'Logistic regression': lm2_score,\n",
    "         'Random Forest': rf_score\n",
    "    }\n",
    "    return res\n",
    "\n",
    "model_baseline(tr_vect, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling results: {'Logistic regression': 0.8839971555155985,\n",
    " 'Random Forest': 0.8198122061915403}  \n",
    "Normal results: {'Logistic regression': 0.7273105816751935, 'Random Forest': 0.728039714039031}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:39:53.743301Z",
     "start_time": "2019-03-01T21:39:49.595330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8846379074760883"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "clf.fit(tr_vect, y_train)\n",
    "\n",
    "pred =  clf.predict(ts_vect)\n",
    "f1_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic neural net also did well at 88% f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:39:53.749965Z",
     "start_time": "2019-03-01T21:39:53.747559Z"
    }
   },
   "outputs": [],
   "source": [
    "#RUN ONCE TO SAVE MODEL\n",
    "# import pickle\n",
    "# with open('lr_undersampled_model.pickle', 'wb') as handle:\n",
    "#      pickle.dump(lr, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#RUN ONCE TO SAVE FIT VECTORIZER\n",
    "# with open('fit_undersampled_vect.pickle', 'wb') as handle:\n",
    "#      pickle.dump(vect_word, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score on holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T21:39:53.935792Z",
     "start_time": "2019-03-01T21:39:53.755254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.886873350923483"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=2,random_state = 42, class_weight = 'balanced')\n",
    "lr.fit(tr_vect, y_train)\n",
    "pred =  lr.predict(holdout_vect)\n",
    "f1_score(y_holdout,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Donald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T23:23:13.196781Z",
     "start_time": "2019-02-28T23:23:13.156491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of The_Donald titles predicted as toxic 0.27062374245472837\n"
     ]
    }
   ],
   "source": [
    "donald_df = pd.read_csv('new_The_Donald_posts.csv')\n",
    "donald_vect = vect_word.transform(donald_df['title'])\n",
    "donald_preds =  lr.predict(donald_vect)\n",
    "print(f'Percentage of The_Donald titles predicted as toxic {donald_preds.sum()/donald_preds.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T23:26:48.351706Z",
     "start_time": "2019-02-28T23:26:48.346111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Liar Liar Pants on fire', 'Know thy enemy',\n",
       "       'Kamala Harris’s dad: Our family wants to ‘dissociate ourselves from this travesty’',\n",
       "       'Prosecutor: Jussie Smollett Faces Up To 3 Years in Prison',\n",
       "       \"It's almost like the national media isn't interested in certain hate crimes, like this for some reason. I can't quite put my finger on it...\",\n",
       "       \"$6million? Thats a lot of people who won't be getting refunds...\",\n",
       "       'GEOTUS does not get enough credit for calling ISIS, “ISIS” and not “ISIL” like Malik’s brother.',\n",
       "       'The White House on Twitter: \"When America can’t vet who crosses its borders, our citizens, including our legal immigrants, pay the price. This crisis is real—and pretending it doesn’t exist is an insult to those who live with its consequences every day.\"',\n",
       "       'LOL',\n",
       "       \"Can we get some love for Glenn Greenwald. He tells it like it is and doesn't care if feathers get ruffled.\",\n",
       "       'Geesus. What a incredible woman.', 'CAUGHT IN A SMOLLETT',\n",
       "       'Holy hell, the savage!',\n",
       "       'Stupid Criminal Alert: Video Shows Brothers Linked To Jussie Smollett Attack Buying Items Allegedly Worn In Assault',\n",
       "       'LULZ', 'Democrats in 2020',\n",
       "       'Ilhan Omar Makes History as First Openly Anti-Semitic U.S. Representative [OC]',\n",
       "       'Border Wall HYPOCRITES❗️',\n",
       "       'WTF? Jussie Smollett charged with disorderly conducted for allegedly filing false report about attack',\n",
       "       \"If You Don't Want a Wall, You Can Go Fuck Yourself\",\n",
       "       'Hate is dying in America and the democrats are furiously working to resuscitate it.',\n",
       "       'Her parents refused to have an abortion; now, she marches for life',\n",
       "       'AHAHAHAHAHAHAHAHAHA Anti-Trump protesters say plow driver splashed them on purpose',\n",
       "       \"'Pompeo says ISIS bride cannot return to US because she is not a citizen' Sounds like the powers to be stripped this traitor cunt of her citizenship... Rightfully so, IMO.\",\n",
       "       'Breaking news: Smollett is a scumbag!'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donald_df[np.isin(donald_preds, 1)]['title'].values[:25] #these are the ones it said were not okay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T01:47:32.267724Z",
     "start_time": "2019-03-01T01:47:32.262254Z"
    }
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client[\"reddit\"]\n",
    "titles_collection = db.get_collection('titles')\n",
    "overnight_reddit_collection = db.get_collection('overnight_reddit')\n",
    "reddit_overnight_collection = db.get_collection('reddit_overnight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T01:50:18.708107Z",
     "start_time": "2019-03-01T01:50:16.050123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Politics titles predicted as toxic 0.1443013698630137\n"
     ]
    }
   ],
   "source": [
    "subreddit = 'politics'\n",
    "politics_submissions = list(titles_collection.find({'subreddit':subreddit}))\n",
    "politics_text = np.array([i['title'] for i in politics_submissions])\n",
    "politics_vect = vect_word.transform(politics_text)\n",
    "politics_preds = lr.predict(politics_vect)\n",
    "print(f'Percentage of Politics titles predicted as toxic {politics_preds.sum()/politics_preds.shape[0]}')\n",
    "politics_text[np.isin(politics_preds, 1)][:25] #these are the ones it said were not okay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T01:53:03.805353Z",
     "start_time": "2019-03-01T01:53:03.801332Z"
    }
   },
   "source": [
    "### Let's generalize this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T02:00:21.227421Z",
     "start_time": "2019-03-01T02:00:21.222489Z"
    }
   },
   "outputs": [],
   "source": [
    "def subredddit_toxicity_percent(subreddit):\n",
    "    sub_submissions = list(titles_collection.find({'subreddit':subreddit}))\n",
    "    sub_text = np.array([i['title'] for i in sub_submissions])\n",
    "    sub_vect = vect_word.transform(sub_text)\n",
    "    sub_preds = lr.predict(sub_vect)\n",
    "    print(f'Percentage of {subreddit} titles predicted as toxic {politics_preds.sum()/politics_preds.shape[0]}')\n",
    "    twenty_five_samples = sub_text[np.isin(sub_preds, 1)][:25]\n",
    "    print(twenty_five_samples) #these are the ones it said were not okay.\n",
    "    return twenty_five_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T02:00:27.323718Z",
     "start_time": "2019-03-01T02:00:24.917301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of mylittlepony titles predicted as toxic 0.1443013698630137\n",
      "['Equestria Girls Rainbow Dash in Gala Dress' 'Shame'\n",
      " 'The Real Pinkie Pie by Adlynh on DeviantArt'\n",
      " 'Applejack Dressed Like Samus'\n",
      " 'Pony Puppet Theater (Pilot) by MangaMeister on DeviantArt'\n",
      " \"'Told you you would like it, dear' by aJVL\"\n",
      " 'Pony Puppet Theater #6 Pony Rumors by MangaMeister on DeviantArt'\n",
      " 'Without a Care' 'Child of Light' 'Hey Applejack! by Aureai'\n",
      " 'Princess Luna at insane speeds.' 'Huh? by wandrevieira1994'\n",
      " '\"I\\'m Gonna Marry The Princess!\" by dm29'\n",
      " 'Applejack the Awesome Alicorn!'\n",
      " \"Those faces..They're just so..mesmerizing..\"\n",
      " 'A Typical Princess Morning' 'Got Your Nose'\n",
      " 'Fluttershy has an evil side' \"(RariJack Daily) What's Wrong?\"\n",
      " 'A mugs life by pepooni' 'Vigors Are Your Friends, RD by Underpable'\n",
      " \"Everyone of you guys matters, don't let anyone change that\"\n",
      " 'Oh how the tables have turned...' 'Rarijack-Daily: Reading!'\n",
      " 'Octavia helping me to not afk out while waiting on Poundfist to spawn in WoW']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Equestria Girls Rainbow Dash in Gala Dress', 'Shame',\n",
       "       'The Real Pinkie Pie by Adlynh on DeviantArt',\n",
       "       'Applejack Dressed Like Samus',\n",
       "       'Pony Puppet Theater (Pilot) by MangaMeister on DeviantArt',\n",
       "       \"'Told you you would like it, dear' by aJVL\",\n",
       "       'Pony Puppet Theater #6 Pony Rumors by MangaMeister on DeviantArt',\n",
       "       'Without a Care', 'Child of Light', 'Hey Applejack! by Aureai',\n",
       "       'Princess Luna at insane speeds.', 'Huh? by wandrevieira1994',\n",
       "       '\"I\\'m Gonna Marry The Princess!\" by dm29',\n",
       "       'Applejack the Awesome Alicorn!',\n",
       "       \"Those faces..They're just so..mesmerizing..\",\n",
       "       'A Typical Princess Morning', 'Got Your Nose',\n",
       "       'Fluttershy has an evil side', \"(RariJack Daily) What's Wrong?\",\n",
       "       'A mugs life by pepooni',\n",
       "       'Vigors Are Your Friends, RD by Underpable',\n",
       "       \"Everyone of you guys matters, don't let anyone change that\",\n",
       "       'Oh how the tables have turned...', 'Rarijack-Daily: Reading!',\n",
       "       'Octavia helping me to not afk out while waiting on Poundfist to spawn in WoW'],\n",
       "      dtype='<U299')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subredddit_toxicity_percent('mylittlepony')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fab7e57c-fa64-4540-a53e-085f849d42ca",
    "_uuid": "b15c44a583628a0a72036536e8a5fdb67273a4ae"
   },
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:49:02.757769Z",
     "start_time": "2019-02-27T00:49:02.751949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.898% of my data is non-toxic\n"
     ]
    }
   ],
   "source": [
    "non_toxic_percent = len(y_train[y_train['sum']==0]['sum'])/y_train.shape[0]\n",
    "print (f'{round(non_toxic_percent,3)}% of my data is non-toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:53:44.487599Z",
     "start_time": "2019-02-27T00:53:44.482453Z"
    }
   },
   "outputs": [],
   "source": [
    "def score_rf_lr(x,y):\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(x, y)\n",
    "    pred =  rf.predict(ts_vect)\n",
    "    rf_f1 = f1_score(y_test['sum'],pred)\n",
    "\n",
    "    lr = LogisticRegression(C=2,random_state = 42,class_weight = 'balanced')\n",
    "    lr.fit(x, y)\n",
    "    pred =  lr.predict(ts_vect)\n",
    "    lr_f1 = f1_score(y_test['sum'],pred)\n",
    "\n",
    "    print (f'LR F1={lr_f1}, RF F1={rf_f1}')\n",
    "    return lr_f1, rf_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:54:19.035545Z",
     "start_time": "2019-02-27T00:54:07.326788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR F1=0.7404616109279322, RF F1=0.6480086114101185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7404616109279322, 0.6480086114101185)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random OverSampler - about 3x size of dataset\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_sample(tr_vect,y_train['sum'])\n",
    "# X_resampled_df = pd.DataFrame(X_resampled)\n",
    "# model_baseline(X_resampled_df, y_resampled)\n",
    "\n",
    "score_rf_lr(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class imbalance fixing boosts score 30%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:55:00.857241Z",
     "start_time": "2019-02-27T00:54:25.327770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR F1=0.6177054386661374, RF F1=0.5985169491525424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6177054386661374, 0.5985169491525424)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smoted, y_smoted = SMOTE(random_state=42).fit_sample(tr_vect,y_train['sum'])\n",
    "score_rf_lr(X_smoted,y_smoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:55:35.279718Z",
     "start_time": "2019-02-27T00:55:03.308057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR F1=0.6068540623796689, RF F1=0.6101694915254238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6068540623796689, 0.6101694915254238)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_adasyn, y_adasyn = ADASYN(random_state=42).fit_sample(tr_vect,y_train['sum'])\n",
    "score_rf_lr(X_adasyn, y_adasyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random oversampling seems to do best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use this to predict our good and bad subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:53:12.750955Z",
     "start_time": "2019-02-27T00:53:12.745789Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_resampled, y_resampled)\n",
    "pred =  rf.predict(ts_vect)\n",
    "rf_f1 = f1_score(y_test['sum'],pred)\n",
    "\n",
    "lr = LogisticRegression(C=2,random_state = 42,class_weight = 'balanced')\n",
    "lr.fit(X_resampled, y_resampled)\n",
    "pred =  lr.predict(ts_vect)\n",
    "lr_f1 = f1_score(y_test['sum'],pred)\n",
    "\n",
    "print (f'LR F1={lr_f1}, RF F1={rf_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:33:24.703062Z",
     "start_time": "2019-02-27T00:33:24.697724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Incel titles predicted as toxic 0.2637913741223671\n",
      "Percentage of Slate titles predicted as toxic 0.06018054162487462\n",
      "Slate is 4.38x better)\n"
     ]
    }
   ],
   "source": [
    "incel_preds = lr.predict(incel_vect)\n",
    "print(f'Percentage of Incel titles predicted as toxic {incel_preds.sum()/incel_preds.shape[0]}')\n",
    "\n",
    "slate_preds = lr.predict(slate_vect)\n",
    "print(f'Percentage of Slate titles predicted as toxic {slate_preds.sum()/slate_preds.shape[0]}')\n",
    "\n",
    "score_ratio = (incel_preds.sum()/incel_preds.shape[0])/(slate_preds.sum()/slate_preds.shape[0]) #good subreddit 13x better.\n",
    "print (f'Slate is {round(score_ratio,2)}x better)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
