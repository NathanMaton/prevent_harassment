{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d894877c-753f-4947-a6a0-8c100b8af6b2",
    "_uuid": "3a208d285d49bbe7c35827de8416e3b7c5c061ae"
   },
   "source": [
    "## Toxic comment classification\n",
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:27:52.696261Z",
     "start_time": "2019-02-27T00:27:51.687664Z"
    },
    "_cell_guid": "fd0d94af-8dcd-4258-92fc-d1c304215a9a",
    "_uuid": "d2539467b6d1fa164da8c43825cd30a124eb9c47"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import log_loss,confusion_matrix,classification_report,roc_curve,auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, precision_recall_curve \n",
    "from sklearn.metrics import confusion_matrix, f1_score, fbeta_score, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy import sparse\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#WARNINGS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "seed = 42\n",
    "# import os\n",
    "# os.environ['OMP_NUM_THREADS'] = '4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4043cdf-f986-42bc-ad09-ea124e152507",
    "_uuid": "6b388128bf18f28c29d66377e9deb5f1ea8067f1"
   },
   "source": [
    "## Read data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:18:31.596157Z",
     "start_time": "2019-02-27T01:18:29.982253Z"
    },
    "_cell_guid": "7ce644b7-5332-40d7-a827-15f6897be5e8",
    "_uuid": "d1134807fc7b6c604f7fbdd42e0f27e69a834337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns in the train data set: (159571, 8)\n"
     ]
    }
   ],
   "source": [
    "toxic = pd.read_csv('toxicity_data/train.csv') #there's also a test dataset but it doesn't have labels b/c kaggle.\n",
    "#test.fillna(' ',inplace=True) - this line can clean up some issues in the test data if you do use it\n",
    "print('Number of rows and columns in the train data set:',toxic.shape)\n",
    "\n",
    "#unlabeled data\n",
    "incel_df = pd.read_csv('new_IncelTears_posts.csv')\n",
    "slate_df = pd.read_csv('new_slatestarcodex_posts.csv')\n",
    "\n",
    "raw_toxic = toxic\n",
    "small_toxic = toxic.sample(50000) # this decreases time from 50 seconds to less\n",
    "#small_toxic = toxic # this is just so I don't have to rename rest of cells\n",
    "\n",
    "#turn multi-class into single class classifier\n",
    "target_col = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n",
    "y = small_toxic[target_col]\n",
    "y['sum'] = y.sum(axis=1).astype(bool).astype(int) \n",
    "\n",
    "# try undersampling\n",
    "\n",
    "small_toxic['target']=y['sum']\n",
    "neg_sample = small_toxic[small_toxic['target']==0].sample(5000)\n",
    "pos_sample = small_toxic[small_toxic['target']==1].sample(5000)\n",
    "\n",
    "all_df = pd.concat([neg_sample,pos_sample])\n",
    "\n",
    "#tried strafying\n",
    "# X_train, X_holdout, y_train, y_holdout = train_test_split(small_toxic, y['sum'], stratify=y['sum'], test_size=0.2, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(small_toxic, y['sum'], stratify=y['sum'], test_size=0.2, random_state=42)\n",
    "\n",
    "#Original code code\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(small_toxic, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train test_size=0.2, random_state=42)\n",
    "\n",
    "## this is for trying on holdout\n",
    "# X_train, X_holdout, y_train, y_holdout = train_test_split(all_df.drop('target',axis=1), all_df['target'], test_size=0.2, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3a73e542-178e-4b3e-ad8c-87e9dc659762",
    "_uuid": "2daff7626ba426dbfa0172b6c3a4351af27cd4e9"
   },
   "source": [
    "## Text preprocessing\n",
    "\n",
    "[source: ](https://www.kaggle.com/him4318/easy-and-fast-lb-044) \n",
    "\n",
    "Term Frequency Inverse Document  Frequency Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:34:46.365543Z",
     "start_time": "2019-02-27T01:34:44.551603Z"
    },
    "_cell_guid": "93502afb-68c7-4cc2-ad03-f71d2b2cbf2a",
    "_uuid": "3d1747c73d3c67c93eb4e7e81de4400276f0580c"
   },
   "outputs": [],
   "source": [
    "vect_word = TfidfVectorizer(max_features=20000, lowercase=True, analyzer='word',\n",
    "                        stop_words= 'english',ngram_range=(1,3),dtype=np.float32)\n",
    "tr_vect = vect_word.fit_transform(X_train['comment_text'])\n",
    "ts_vect = vect_word.transform(X_test['comment_text'])\n",
    "\n",
    "incel_vect = vect_word.transform(incel_df['title'])\n",
    "slate_vect = vect_word.transform(slate_df['title'])\n",
    "\n",
    "#took 50 seconds on 150k samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:18:50.284852Z",
     "start_time": "2019-02-27T01:18:45.485236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic regression': 0.8579194372173925,\n",
       " 'Random Forest': 0.7851350621853507}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_model(model, X_train, y_train):\n",
    "    cv_results = cross_validate(model, X_train, y_train, cv=5, scoring='f1')\n",
    "    return np.mean(cv_results['test_score'])\n",
    "\n",
    "def model_baseline(X_train, y_train):\n",
    "    \"\"\"This takes in training and validation data and runs it through\n",
    "    6 basic classification models and scores them based on recall\"\"\"\n",
    "\n",
    "    lm2 = LogisticRegression(C=2,random_state = 42,class_weight = 'balanced') #all features\n",
    "    lm2_score = score_model(lm2, X_train, y_train)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf_score = score_model(rf, X_train, y_train)\n",
    "\n",
    "    res = {\n",
    "        'Logistic regression': lm2_score,\n",
    "         'Random Forest': rf_score\n",
    "    }\n",
    "    return res\n",
    "\n",
    "model_baseline(tr_vect, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra shit I did with Aaron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:21:04.846391Z",
     "start_time": "2019-02-27T01:21:04.841283Z"
    }
   },
   "outputs": [],
   "source": [
    "def score_rf_lr_under(x,y):\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(x, y)\n",
    "    pred =  rf.predict(ts_vect)\n",
    "    rf_f1 = f1_score(y_test,pred)\n",
    "\n",
    "    lr = LogisticRegression(C=2,random_state = 42, class_weight = 'balanced')\n",
    "    lr.fit(x, y)\n",
    "    pred =  lr.predict(ts_vect)\n",
    "    lr_f1 = f1_score(y_test,pred)\n",
    "\n",
    "    print (f'LR F1={lr_f1}, RF F1={rf_f1}')\n",
    "    return lr_f1, rf_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:21:06.754712Z",
     "start_time": "2019-02-27T01:21:05.949714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR F1=0.8774855676715844, RF F1=0.8040677966101695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8774855676715844, 0.8040677966101695)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rf_lr_under(tr_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:35:08.077468Z",
     "start_time": "2019-02-27T01:35:02.875256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR F1=0.6730122378873542\n"
     ]
    }
   ],
   "source": [
    "### artifical holdout\n",
    "\n",
    "#vect_word = TfidfVectorizer(max_features=20000, lowercase=True, analyzer='word',\n",
    "#                        stop_words= 'english',ngram_range=(1,3),dtype=np.float32)\n",
    "ho_vect = vect_word.transform(small_toxic['comment_text'])\n",
    "# ts_vect = vect_word.transform(X_test['comment_text'])\n",
    "\n",
    "lr = LogisticRegression(C=2,random_state = 42,class_weight = 'balanced')\n",
    "lr.fit(tr_vect,y_train)\n",
    "pred =  lr.predict(ho_vect)\n",
    "lr_f1 = f1_score(small_toxic['target'],pred)\n",
    "\n",
    "print (f'LR F1={lr_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fab7e57c-fa64-4540-a53e-085f849d42ca",
    "_uuid": "b15c44a583628a0a72036536e8a5fdb67273a4ae"
   },
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:49:02.757769Z",
     "start_time": "2019-02-27T00:49:02.751949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.898% of my data is non-toxic\n"
     ]
    }
   ],
   "source": [
    "non_toxic_percent = len(y_train[y_train['sum']==0]['sum'])/y_train.shape[0]\n",
    "print (f'{round(non_toxic_percent,3)}% of my data is non-toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:53:44.487599Z",
     "start_time": "2019-02-27T00:53:44.482453Z"
    }
   },
   "outputs": [],
   "source": [
    "def score_rf_lr(x,y):\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(x, y)\n",
    "    pred =  rf.predict(ts_vect)\n",
    "    rf_f1 = f1_score(y_test['sum'],pred)\n",
    "\n",
    "    lr = LogisticRegression(C=2,random_state = 42,class_weight = 'balanced')\n",
    "    lr.fit(x, y)\n",
    "    pred =  lr.predict(ts_vect)\n",
    "    lr_f1 = f1_score(y_test['sum'],pred)\n",
    "\n",
    "    print (f'LR F1={lr_f1}, RF F1={rf_f1}')\n",
    "    return lr_f1, rf_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:54:19.035545Z",
     "start_time": "2019-02-27T00:54:07.326788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR F1=0.7404616109279322, RF F1=0.6480086114101185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7404616109279322, 0.6480086114101185)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random OverSampler - about 3x size of dataset\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_sample(tr_vect,y_train['sum'])\n",
    "# X_resampled_df = pd.DataFrame(X_resampled)\n",
    "# model_baseline(X_resampled_df, y_resampled)\n",
    "\n",
    "score_rf_lr(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class imbalance fixing boosts score 30%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:55:00.857241Z",
     "start_time": "2019-02-27T00:54:25.327770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR F1=0.6177054386661374, RF F1=0.5985169491525424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6177054386661374, 0.5985169491525424)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smoted, y_smoted = SMOTE(random_state=42).fit_sample(tr_vect,y_train['sum'])\n",
    "score_rf_lr(X_smoted,y_smoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:55:35.279718Z",
     "start_time": "2019-02-27T00:55:03.308057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR F1=0.6068540623796689, RF F1=0.6101694915254238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6068540623796689, 0.6101694915254238)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_adasyn, y_adasyn = ADASYN(random_state=42).fit_sample(tr_vect,y_train['sum'])\n",
    "score_rf_lr(X_adasyn, y_adasyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random oversampling seems to do best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use this to predict our good and bad subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:53:12.750955Z",
     "start_time": "2019-02-27T00:53:12.745789Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_resampled, y_resampled)\n",
    "pred =  rf.predict(ts_vect)\n",
    "rf_f1 = f1_score(y_test['sum'],pred)\n",
    "\n",
    "lr = LogisticRegression(C=2,random_state = 42,class_weight = 'balanced')\n",
    "lr.fit(X_resampled, y_resampled)\n",
    "pred =  lr.predict(ts_vect)\n",
    "lr_f1 = f1_score(y_test['sum'],pred)\n",
    "\n",
    "print (f'LR F1={lr_f1}, RF F1={rf_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:33:24.703062Z",
     "start_time": "2019-02-27T00:33:24.697724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Incel titles predicted as toxic 0.2637913741223671\n",
      "Percentage of Slate titles predicted as toxic 0.06018054162487462\n",
      "Slate is 4.38x better)\n"
     ]
    }
   ],
   "source": [
    "incel_preds = lr.predict(incel_vect)\n",
    "print(f'Percentage of Incel titles predicted as toxic {incel_preds.sum()/incel_preds.shape[0]}')\n",
    "\n",
    "slate_preds = lr.predict(slate_vect)\n",
    "print(f'Percentage of Slate titles predicted as toxic {slate_preds.sum()/slate_preds.shape[0]}')\n",
    "\n",
    "score_ratio = (incel_preds.sum()/incel_preds.shape[0])/(slate_preds.sum()/slate_preds.shape[0]) #good subreddit 13x better.\n",
    "print (f'Slate is {round(score_ratio,2)}x better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T00:38:53.391758Z",
     "start_time": "2019-02-27T00:38:42.304569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "pred =  clf.predict(ts_vect)\n",
    "f1_score(y_test['sum'],pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
